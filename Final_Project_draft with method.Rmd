---
title: "Transcriptome Analysis in Colorectal Cancer Diagnostics"
author: "Group 2: Joudy Raba Bakri Radwan Mouhaffel, Lea Skaar-Henriksen, Haldor Haugen, Gege Liu"
date: "2024-11-08"
output:
  html_document:
    toc: true            
    toc_depth: 4         
    toc_float: true      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

## 1. Introduction

Colorectal cancer (CRC) is one of the most lethal cancers, which stresses the importance of new diagnostic approaches. For the BIN315 course project, our group selected the TCGA-COAD dataset which is a part of the Cancer Genome Atlas initiative that focuses on colorectal cancer. This was done to be able to utilize the knowledge gained in this class on differential gene expression analysis, machine learning and enrichment analysis to gain a better insight into this disease. 

The TCGA-COAD dataset contains a large amount of RNA-Seq data which makes it possible to analyze gene expression in primary tumor and solid normal tissues in detail. RNA-Seq technology is very relevant for these studies since it enables the authors to determine which genes are differentially expressed and which pathways are affected during cancer progression, including the Wnt signaling pathway and the extracellular matrix remodeling. The results of these analyses are the presented with the goal of improving classification using Random Forests and K-Nearest, as well as discovering new biomarkers with diagnostic value. 

This paper Here, on presents we employ molecular pipeline an mechanism for integrated of the approach CRC. In this project, we not only aimed to identify differentially expressed genes and stable biomarkers, but also employed machine learning models and performed functional enrichment analysis to provide research analysis. At the same time, this work presents the real-life use of various bioinformatics tools and techniques learned in this course.

### 1.1 Dataset

In this study, we utilized the TCGA-COAD dataset, which is publicly available through the Cancer Genome Atlas (TCGA) research network at <https://portal.gdc.cancer.gov/>, and contains multi-omics data. We specifically focused on RNA-Seq data, accessed via the TCGAbiolinks R package[1]. This dataset includes a key attribute, sample_type, which allows us to distinguish between primary tumor samples and solid tissue normal samples, making it well-suited for classification analysis.

## 2. Methods

### 2.1 Libraries

The libraries used in our analysis are listed below.

```{r library, echo=FALSE, results='hide'}
suppressMessages({
  # Ensure BiocManager is installed
  if (!requireNamespace("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
  }
  
  # Install required Bioconductor packages if not already installed
  required_packages <- c("TCGAbiolinks", "edgeR", "SummarizedExperiment")
  for (pkg in required_packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
      BiocManager::install(pkg)
    }
  }
})
```

```{r library-show, results='hide'}
suppressMessages({
library(TCGAbiolinks)
library(SummarizedExperiment)
library(edgeR)
library(DESeq2)
library(tidyverse)
library(matrixStats)
library(clusterProfiler)
library(org.Hs.eg.db)
library(dplyr)
library(caret)
library(class)
library(smotefamily)
library(randomForest)
})
```

### 2.2 Principal Component Analysis

PCA is an unsupervised dimensionality reduction method that transforms the original feature set into a set of linearly independent variables, i.e., principal components. This transformation can help us not only retain most of the original information when selecting several principle components, but also improve computational efficiency, reduce noise, and enable dataset visualization and feature selection [3]. We tired to performs principal component analysis by the prcomp() function to better understand our dataset and choose the number of principal components for dimensionality reduction.

### 2.3 Differential Expression Analysis

The purpose of differential expression analysis in this study is to find out the genes whose expression data are upregulated or downregulated in normal samples and cancer samples through statistical tests. This approach helps to provide important insights for cancer research and find the potential biomarkers and mechanisms associated with tumor progression and recurrence [4].

Here, we utilize the DESeq2 package, which is widely-used tool for differential genes analysis of RNA-seq data. DESeq2 package apply the negative binomial models to fit the count-based RNA-Seq data which is different from Limma package that uses linear linear models for the microarray data, as the RNA-Seq data has discrete and over-dispersed characteristics. The key steps in DESeq2 differential expression analysis include data normalization, fitting a negative binomial distribution, estimating dispersion, performing differential expression testing, and correcting for multiple hypothesis testing. Then, the threshold needs to be carefully selected when identifying DEGs (Differentially Expressed Genes), which is an important step to ensure the reliability and accuracy of the analysis results. The choice of measuring statistical significance, such as p-value, p-value adjusted by different techniques (padj), and the size of the difference (expressed as log2 fold change (l2FC)), is crucial because it actually directly affects the reliability of the results and the interpretation of the data [4].

### 2.4 Supervised Methods

#### 2.4.1 Class Balance

Class balance is a method to combat data imbalance when analysing data. This imbalance occurs as a consequence of the difference in availability of tissue samples. The chosen dataset exhibits a significant class imbalance, with far more Tumor samples (378) than Normal samples (41). Addressing this imbalance is crucial to ensure unbiased model performance and reliable predictions. Common approaches to tackle imbalance include undersampling the majority class, oversampling the minority class, generating synthetic samples or applying class weights.

The chosen method for class balance in this study was weighting, in order to address the imbalance. This method adjusts for class frequency by assigning weights inversely proportional to class size, ensuring that both classes are fairly represented during modeling. The benefits of weighting is that it retains all original data, preserving its integrity, and avoids the computational overhead of generating synthetic samples with other methods like SMOTE. Additionally, it is particularly effective for high-dimensional data, where oversampling methods may struggle with the curse of dimentionality. Also it is more efficient and requires less computational power.

#### 2.4.2 Random forest(RF)

Random Forest modelling is well-suited for high-dimensional data, performing effectively with a large number of features without the need for explicit dimentionality reduction. It is robust to overfitting due to its ensemble approach, which combines multiple decision trees to improve generalization and reduce variance. Additionally, Random Forest naturally handles class imbalance by allowing the adjustment of class weights (classwt), ensuring fair representation of minority classes during model training.

#### 2.4.3 K-nearest neighbour(KNN)

K-nearest neighbour is another supervised method that looks at similar samples in feature space to determine what class the observation belongs in. Unlike random forest this method is prone to overfitting, and not very well suited for high-dimentional data, which in turn means dimentionality reduction like PCA is preferable for the method to provide useful data. K-nearest neighbour also struggles with imbalanced data, which is the reason weighted kNN is being utilized in this study.

#### 2.4.4 Evaluation

Model evaluation is a method of ensuring accurate and reliable performance of models utilized in data analysis. The different methods used in this study are accuracy and error rate, confusion matrix and cross-validation. Accuracy is used to measure samples correctly classified, and error rate is used to determine incorrect predictions. Together they reflect the effectiveness of the model. Confusion matrix provides a breakdown of how well a model, like RF, performs for each class. Lastly, cross-validation is used to ensure the model performs well on unseen data, by attempting to detect potential overfitting. It does this by training on one part of the data, and testing on another unseen part of the data to make sure the model doesn't pick up noise from the training data that won't translate to the test data.

### 2.5 Go Enrichment analysis

Gene Ontology (GO) enrichment analysis is a method used to highlight key biological processes associated with genes that distinguished tumor and normal samples. After differential expression analysis, significantly up-and down-regulated genes, aswell as genes detected through RF, can be further analysed to gain insight into the function of the genes by linking these genes to relevant biological processes. This analysis allows for the identification of key mechanisms and pathways related to colorectal cancer.


## 3. Results

The Results section contains the analysis and results of a series of processes including preprocessing, PCA, differential analysis, and modeling using machine learning algorithms.

### 3.1 Exploring and preprocessing

```{r load data from TCGA, echo=FALSE, results='hide'}
# 1. Download RNA-Seq data for selected projects
# sink(tempfile())
# suppressMessages({
# query <- GDCquery(
#   project = "TCGA-COAD",
#   data.category = "Transcriptome Profiling",
#   data.type = "Gene Expression Quantification",
#   workflow.type = "STAR - Counts"
# )
# GDCdownload(query, method = "api", files.per.chunk = 10)
# data <- GDCprepare(query)
# })
# sink()
# 
# # 2. Select the tumor samples and normal samples
# filtered_samples <- colData(data)$sample_type %in% c("Primary Tumor", "Solid Tissue Normal")
# data_filtered <- assays(data)$unstranded[, filtered_samples]
# dim(data_filtered) # 60661 genes 522 samples
# sample_types_filtered <- colData(data)$sample_type[filtered_samples]
# table(sample_types_filtered)  ##Primary Tumor: 481; Solid Tissue Normal:41
# 
# saveRDS(data_filtered, file = "data_filtered.rds")
# saveRDS(sample_types_filtered, file = "sample_types_filtered.rds")
```

#### 3.1.1 Exploring

This dataset contains gene expression data of various samples. It consists of 522 columns (each column represents a different sample) and 60,660 rows (each row corresponds to a gene transcript).

```{r load data}
data_filtered <- readRDS("data_filtered.rds")
sample_types_filtered <- readRDS("sample_types_filtered.rds")
data.counts <- data.frame(data_filtered)
dim(data.counts)
data.counts[1:5,1:2]
```

Then, a sample type distribution plot was drawn, with 481 “primary tumor” type samples and 41 “solid tissue normal” type samples. It can be seen that the number of tumor samples is higher than that of normal tissue samples.

```{r Exploring 1}
names(sample_types_filtered) <- colnames(data.counts)
sample_info <- data.frame(Sample = names(sample_types_filtered), SampleType = sample_types_filtered)

# Plot the distribution
sample_info %>% 
  group_by(SampleType) %>% 
  summarize(Count = n()) %>% 
  ggplot(aes(x = SampleType, y = Count, fill = SampleType)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  labs(title = "Fig.1. Sample Type Distribution", x = "Sample Type", y = "Count") + 
  theme(plot.title = element_text(hjust = 0.5))
```

#### 3.1.2 Preprocessing

We observed that most genes in the dataset have only one transcript, and a few genes (such as ENSG00000002586.20 and ENSG00000002586.20_PAR_Y) have two transcripts. Meanwhile, the ENSG00000002586.20_PAR_Y transcript has zero expression across all samples, providing no meaningful information for downstream analyses.

```{r Preprocessing-1}
data.counts %>%
  rownames_to_column(var = "Gene") %>% 
  filter(Gene %in% c("ENSG00000002586.20", "ENSG00000002586.20_PAR_Y")) %>% 
  dplyr::select(1:3)
```

Therefore, removing these redundant transcripts can help simplify the dataset and reduce noise while retaining the biological significance of most of the data. After excluding 44 invalid transcripts, we also removed the transcript IDs from the gene names. In addition, considering that the upcoming analysis will involve DESeq2, DESeq2 recommends using safe characters in column names and row names to avoid potential problems. So, we replaced the '.' character in the sample type name with a '-' character.

```{r Preprocessing-2}
data.counts <- data.counts %>% 
  rownames_to_column(var = "Gene") %>%
  filter(!grepl("_PAR", Gene)) %>%
  mutate(Gene = sub("\\..*", "", Gene))

sample_types_filtered <- gsub(" ", "_", sample_types_filtered) 
```

#### 3.1.3 Quality control

From the figure below, we can see that the total reads of most samples are in the range of 2e+07 to 6e+07. The lower reads on the left side of the histogram indicate that that the sequencing depth of some samples may be low, which may mean that the gene expression in these samples is low. To improve the quality and reliability of downstream data analysis, we performed quality control, such as removing low-quality genes and samples.

```{r Filtering-1}
anyNA(data.counts)

data.counts <- data.counts %>% 
  column_to_rownames(var = 'Gene')
sample_totals <- colSums(data.counts)
sample_totals_df <- data.frame(TotalCounts = sample_totals)

ggplot(sample_totals_df, aes(x = TotalCounts)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "grey") +
  labs(title = "Fig.2. Total Reads per Sample", x = "Total Counts", y = "Frequency") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

First, we removed some low-quality samples with less than 20 million expression data. Next, from the gene perspective, we removed genes with low expression in most samples based on the log2 (CPM) transformation of the expression data. After the above steps, the cleaned dataset retained 14,633 genes and 427 samples.

```{r Filtering-2}
# 1. Sample must have 20M reads
idx <- colSums(data.counts) >= 20E6
data.counts.new <- data.counts[,idx]
sample_types_filtered <- sample_types_filtered[idx]
dim(data.counts.new) #60616   427
# 2. Filtering out lowly expressed genes based on the log2(CPM)
data.counts.cpm <- cpm(data.counts.new, log = TRUE)
proportion_threshold <- 0.05
num_samples <- ncol(data.counts.new)
keep_genes <- rowSums(data.counts.cpm > 1) >= (proportion_threshold * num_samples)
data.counts.new = data.counts.new[keep_genes, ]
dim(data.counts.new)
#rm(data.counts.cpm)
```

#### 3.1.4 Normalization

```{r Normalization-VST}
data_vst <- DESeq2::varianceStabilizingTransformation(as.matrix(data.counts.new))
data_vst <- data_vst - min(data_vst)
```

```{r Normalization-VST2}
# # Plot the expression profile of a random gene after the normalization 
# set.seed(3)
# 
# data_vst %>% 
#   as.data.frame() %>% 
#   rownames_to_column(var = "Gene") %>% 
#   filter(Gene == sample(rownames(data_vst),1)) %>% 
#   pivot_longer(-Gene, names_to = "Sample", values_to = "Expression") %>% 
#   mutate(Sample = as.numeric(row_number())) %>% 
#   ggplot(aes(x = Sample, y = Expression)) +
#   geom_line() +
#   theme_bw()

```

### 3.2 PCA

#### 3.2.1 PCA Computation

The results of the PCA are illustrated in Fig. 3 and Fig. 4, which depict the cumulative variance explained by the principal components and the dataset visualization based on PC1 and PC2, respectively.

As can be seen from the table below and Fig.3, the first two components only explain 26.92% of the cumulative variance, which is not very ideal. However, the first 20 principal components can explain 64% of the cumulative variance.

We can consider the reasons behind the low proportion of variance explained by the first two principal components. First of all, the dataset includes over 14,000 genes, which creates a very high-dimensional data space. However, we only have about 400 samples, which is much smaller than the number of genes. This imbalance makes it harder to capture the variation, since the dimentionality reductions works better with more samples. Secondly, many genes in the dataset are highly correlated, which adds complexity to the data, resulting each components can explain less variance. Lastly, gene expression data naturally have complex patterns and interactions between genes, making it difficult for the first few principal components to capture a large proportion of the variance.

```{r PCA1}
# Perform the PCA
data.pca <- prcomp(t(data_vst))

# Summary of components
cumulative_variance <- summary(data.pca)$importance[3,]
cumulative_variance[1:30] # show the first 30 principle components
```

Beyond the 60th principal component, the curve of cumulative variance is smoother, indicating that the contributions of other components gradually decrease.

```{r PCA2}
# Plot the cumulative variance explained by the principle components
variance_df <- data.frame(PC = seq_along(cumulative_variance),CumulativeVariance = cumulative_variance)

ggplot(variance_df, aes(x = PC, y = CumulativeVariance)) +
  geom_line(color = "black") +
  geom_point(color = "lightblue") + 
  theme_bw() + 
  labs( title = "Fig.3. Cumulative Variance Ratio", 
        x = "Numbers of Principal Components", 
        y = "Cumulative Variance Explained"
        ) +
  scale_x_continuous(breaks = seq(0, length(cumulative_variance), by = 20)) +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

In order to interpret our principal components, we hope to find which genes have the greatest impact on each PC. However, the number of original genes is too large, so we focus on the top ten important genes affecting PC1 and PC2.

```{r PCA3}
pc_loadings <- data.pca$rotation

pc_loadings <- pc_loadings %>% 
  as_tibble(rownames = "gene")

genes_pc1 <- pc_loadings %>%
  dplyr::select(gene, PC1) %>%
  pivot_longer(matches("PC"), names_to = "PC", values_to = "loading") %>% 
  group_by(PC) %>% 
  arrange(desc(abs(loading))) %>% 
  slice(1:10) %>% 
  pull(gene) %>% 
  unique()

print(genes_pc1)

genes_pc2 <- pc_loadings %>%
  dplyr::select(gene, PC2) %>%
  pivot_longer(matches("PC"), names_to = "PC", values_to = "loading") %>% 
  group_by(PC) %>% 
  arrange(desc(abs(loading))) %>% 
  slice(1:10) %>% 
  pull(gene) %>% 
  unique()

print(genes_pc2)

```

#### 3.2.3 Visualization on the First Two Principal Components

Then, we turn to visualize our samples on PC1 and PC2 space and distinguish the two classes. In this plot, there is a clear distinction between the primary tumor and solid tissue normal samples. The two classes are mostly separated by PC1, with primary tumors showing a more scattered distribution. And there are a few potential outliers in the lower right of the plot.

```{r PCA4}
classes <- sample_types_filtered %>% factor()

data.pca$x %>% 
  ggplot(aes(PC1, PC2, col = classes)) +
  geom_point() +
  labs(title = "Fig.4. PCA Visualization", x = "PC1", y = "PC2") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
```

#### 3.2.4 Outlier Detection through PCA

Therefore, we tried to check the potential outliers found before and remove them, because the number of these outliers was very small, only 8 samples, and these outliers could have a great impact on the subsequent analysis, so we decided to remove them and perform the PCA analysis again to check the results of the before and after PCA.

```{r PCA5}
# Try to find outliers
pca_projection <- data.frame(Sample = rownames(data.pca$x), 
                             PC1 = data.pca$x[, 1], 
                             PC2 = data.pca$x[, 2])

outliers <- pca_projection %>% 
  filter(PC2 < -100)

rownames(outliers)

# Delete the outliers from the dataset
idx_2 <- which(colnames(data_vst) %in% rownames(outliers))

sample_types_filtered_new <- sample_types_filtered[-idx_2]
data_vst <- data_vst %>% 
  as.data.frame() %>% 
  dplyr::select(-rownames(outliers))
```

Now, we can see that the new samples based on PC1 and PC2 are more reasonably distributed, and PC1 seems to play a greater role in splitting the two classes.

```{r PCA6, echo=FALSE}
# Perform the PCA
data.pca <- prcomp(t(data_vst))
classes_new <- sample_types_filtered_new %>% factor()

data.pca$x %>% 
  ggplot(aes(PC1, PC2, col = classes_new)) +
  geom_point() +
  labs(title = "Fig.5. PCA Visualization", x = "PC1", y = "PC2") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
```

### 3.3 Differential Expression Analysis

#### 3.3.1 Calculation and filtering the DEGs

Here, we create a dataset object and specify the experimental conditions (such as "primary tumor" and "solid tissue normal") though the DESeqDataSetFromMatrix function. Then we use the DESeq function to perform differential expression analysis and extract the analysis results.

```{r DEA1}
# Delete the outliers from the dataset
data.counts.new2 <- data.counts.new %>% 
  as.data.frame() %>% 
  dplyr::select(-rownames(outliers))
dim(data.counts.new2) #17129   419

# Read in RNA-Seq count data and design
suppressMessages({
dds <- DESeq2::DESeqDataSetFromMatrix(
  countData = as.matrix(data.counts.new2),
  colData = data.frame(condition = factor(classes_new, levels = c("Primary_Tumor","Solid_Tissue_Normal"))),
  design = ~ condition)

dds <- DESeq2::DESeq(dds)
res <- DESeq2::results(dds)
as.data.frame(res)[1:10,]
res <- as.data.frame(res)
})
```

Then, we screened out differentially expressed genes based on log2FoldChange and padj, and the thresholds of these two parameters were selected based on the Maurya paper [2]. A total of 2803 genes were screened, including 1389 up-regulated genes and 1414 down-regulated genes.

```{r DEA2}
res0.05 <- res %>% 
  filter(padj< 0.01 & abs(log2FoldChange)>1.5) %>% 
  arrange(padj)

dim(res0.05)

DEGs_up_genes <- res0.05[res0.05$log2FoldChange>0,] %>% 
  rownames_to_column("Gene") %>% 
  dplyr::select("Gene") %>% 
  pull("Gene")

head(res0.05[res0.05$log2FoldChange>0,])
  
DEGs_down_genes <- res0.05[res0.05$log2FoldChange<0,] %>% 
  rownames_to_column("Gene") %>% 
  dplyr::select("Gene") %>% 
  pull("Gene")

head(res0.05[res0.05$log2FoldChange<0,])

#The number of upregulated genes
print(length(DEGs_up_genes))

#The number of downregulated genes
print(length(DEGs_down_genes))
```

#### 3.3.2 Volcano plot

Finally, the results can be visualized to easily observe patterns and gain some potential understanding.

```{r DEA3}
res %>% 
  filter(baseMean>0 & log2FoldChange > -10 & !is.na(padj)) %>% 
  mutate(DEGs = ifelse(padj< 0.01 & abs(log2FoldChange)>1.5 , "TRUE", "FALSE")) %>% 
  ggplot(aes(x = log2FoldChange, y = 1/padj, color = DEGs )) +
  geom_point(size = 1) +
  scale_y_log10() +
  labs(x = "log2FoldChange", y = "-log10(padj)", title = "Fig.6. Volcano plot") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

### 3.4 Modelling

#### 3.4.1 Train-test split

The dataset was divided into training (70%) and test (30%) sets following normalization. The larger portion will be used to train the model and the other to evaluate the model's performance on unseen data. A stratified splitting approach was used to maintain class proportions, ensuring that both sets are representative of the full dataset, and doesn't contain a skewed proportion of Tumor vs Normal samples.

```{r Train-test split}
# Perform train-test split on VST-normalized data
set.seed(42)  # For reproducibility
vst_matrix <- data_vst
table(classes_new)
train_idx <- createDataPartition(classes_new, p = 0.7, list = FALSE)

# Subset normalized data and labels
train_features <- t(vst_matrix[, train_idx])  # Transpose for modeling
test_features <- t(vst_matrix[, -train_idx])  # Transpose for modeling
train_labels <- as.factor(sample_types_filtered_new[train_idx])
test_labels <- as.factor(sample_types_filtered_new[-train_idx])
```

#### 3.4.2 Data Balancing

Since dataset exhibits a significant class imbalance, with far more Tumor samples (378) than Normal samples (41), we chose to apply weighting in order to address the imbalance.

```{r Data Balancing}
# Calculate class weights
class_counts <- table(train_labels)
class_weights <- max(class_counts) / class_counts
print(class_weights)
```

Weighting modifies the importance of each class by assigning weights inversely proportional to their frequencies. This way, predictions favor neither the majority nor the minority class.

#### 3.4.3 Weighted k-Nearest Neighbors (kNN)

##### Training the Model

```{r knn train}
set.seed(42)
weighted_knn <- train(
  x = train_features,
  y = train_labels,
  method = "knn",
  tuneGrid = expand.grid(k = seq(3, 15, by = 2)),  # Odd k values
  trControl = trainControl(method = "cv", number = 10, classProbs = TRUE),
  weights = as.numeric(class_weights[train_labels])  # Apply class weights
)

# Display the best k value
cat("Best k value:", weighted_knn$bestTune$k, "\n")
```

The kNN model was trained using weighted class frequencies to address imbalance. The optimal value of k, 11 was determined using 10-fold cross-validation.

##### Making Predictions

```{r knn prediction}
# Make predictions
predicted_labels <- predict(weighted_knn, newdata = test_features)
```

##### Evaluating the model

```{r knn evaluation}
# Confusion matrix
confusion <- table(Real = test_labels, Predicted = predicted_labels)
print(confusion)

# Accuracy and error rate
accuracy <- sum(diag(confusion)) / sum(confusion)
cat("Accuracy:", accuracy, "\n")
error <- 1 - accuracy
cat("Error rate:", error, "\n")
```

The model has an accuracy of 100%. It may indicate overfitting or Data leakage.

#### 3.4.4 Random Forest

The same random split as used in the k-NN model was applied to maintain consistency.

##### Training the Model

```{r rf train}
# Train a random forest model
rf_model <- randomForest(
  x = train_features,
  y = train_labels,
  ntree = 500,              # Number of trees
  mtry = sqrt(ncol(train_features)),  # Features tried at each split
  classwt = as.numeric(class_weights),  # Apply class weights
  importance = TRUE         # Enable feature importance calculation
)

# Print model summary
print(rf_model)
```

A Random Forest model was trained using 500 trees and weighted class frequencies to address imbalance. Feature importance was calculated to identify key contributors to classification.

##### Making Predictions

```{r rf prediction}
# Make predictions
rf_predictions <- predict(rf_model, newdata = test_features)
```

##### Evaluating the model

```{r evaluation}
# Confusion matrix
confusion <- table(Real = test_labels, Predicted = rf_predictions)
print(confusion)

# Accuracy and error rate
accuracy <- sum(diag(confusion)) / sum(confusion)
cat("Accuracy:", accuracy, "\n")
error <- 1 - accuracy
cat("Error rate:", error, "\n")
```

The confusion matrix, accuracy, and error rate were calculated to evaluate the performance of the Random Forest model. The model has an accuracy of 100%. This could indicate several possibilities. It might be the model is showing excellent performance, with the data set being naturally well-separated. With only 29 samples in the Normal class, the model might perform perfectly due to limited diversity in the minority class. It could also be a result of overfitting, or data leakage. To confirm whether the high accuracy reflects true model performance or something is wrong, we will perform some further testing :

##### Checking the Split

```{r check1}
# Check class distribution in training and test sets
cat("Training set class distribution:\n")
print(table(train_labels))

cat("Test set class distribution:\n")
print(table(test_labels))

```

The splits seem to be even.

##### Test for Data Leakage

```{r check2}
any(duplicated(rbind(train_features, test_features)))

```

##### Evaluate with Cross-Validation

```{r check3}
set.seed(42)
rf_cv <- train(
  x = train_features,
  y = train_labels,
  method = "rf",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(mtry = sqrt(ncol(train_features)))
)
print(rf_cv)

```

The high accuracy and kappa values indicate that the Random Forest model generalizes well across different subsets of the data, and there is no significant sign of overfitting. It seems the model is highly reliable for separating Primary Tumor and Solid Tissue Normal samples. The consistent results across folds highlight the model's reliability and its ability to handle the significant class imbalance effectively.

##### Feature Importance

Feature importance is a metric used to identify the most influential features in a predictive model. In this analysis, it quantifies each feature's contribution to reducing classification uncertainty, measured by the Mean Decrease Gini. In other words, these genes makes the model able to separate the tumor and normal samples. Features with higher importance scores are key drivers of the model's accuracy and therefore may provide insights into the underlying biological processes affected in cancer cells.

```{r feature importance}
# Extract feature importance
importance <- importance(rf_model)
feature_importance <- data.frame(
  Feature = rownames(importance),
  Importance = importance[, "MeanDecreaseGini"]
)

# Top 10 features
top_features <- feature_importance[order(-feature_importance$Importance), ][1:10, ]
print(top_features)
```


```{r plot feature importance}
gene_names <- read.delim("genenames.org.txt", header = TRUE) %>%
  na.omit()

genetable <- rf_model %>% 
  importance() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Genes") %>%
  mutate(Genes = sub("\\..*", "", Genes)) %>%
  left_join(gene_names, by = c("Genes" = "Ensembl.gene.ID")) %>%
  na.omit() %>%
  top_n(10, MeanDecreaseAccuracy) %>%
  arrange(desc(MeanDecreaseAccuracy)) %>%
  dplyr::select("Genes", "MeanDecreaseAccuracy", "Symbol")

# Plot feature importance
ggplot(genetable, aes(x = reorder(Symbol, MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() +
geom_text(aes(label = Genes), size =3, hjust = 1.1) + 
  theme_bw() + 
  labs(
    title = "Fig.7. Top 10 Most Important Features",
    x = "Feature (Gene)",
    y = "Importance (Mean Decrease Accuracy)"
  )+
theme(plot.title = element_text(hjust = 0.5)) 
  
```

The plot visualizes the top 10 most important features in the Random Forest model based on their Mean Decrease Gini values. These features represent the genes that contribute most significantly to reducing impurity in the classification task.

### 3.5 Biological Relevance

#### 3.5.1 GO Analysis of Up/Downregulated Genes

The results shows that the genes upregulated were enriched for gene ontology categories related to immunity and muscle activity, whereas the downregulated genes showed enrichment for gene ontology categories implicated in extracellular matrix organization and Wnt signaling pathway.
```{r Go Analysis1}

go_DEGs_up <- enrichGO(gene = DEGs_up_genes, OrgDb = org.Hs.eg.db, keyType = "ENSEMBL", ont = "BP")
go_DEGs_up_df <- as.data.frame(go_DEGs_up)

go_DEGs_up_df[1:10,2:7]

go_DEGs_down <- enrichGO(gene = DEGs_down_genes, OrgDb = org.Hs.eg.db, keyType = "ENSEMBL", ont = "BP", pvalueCutoff = 0.05)
go_DEGs_down_df <- as.data.frame(go_DEGs_down)

go_DEGs_down_df[1:10,2:7]

```

#### 3.5.2 GO Analysis of genes selected from rf model

The result identified these significant biological processes associated with the top genes separating tumor and normal samples. These findings align with known cancer biology, emphasizing processes involved in cell growth, signaling, and regulation.

```{r Go Analysis2}
selectted_gene <- rf_model %>% 
  importance() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Genes") %>%
  mutate(Genes = sub("\\..*", "", Genes)) %>%
  top_n(1000, MeanDecreaseAccuracy) %>%
  arrange(desc(MeanDecreaseAccuracy)) %>%
  dplyr::select("Genes") %>% 
  pull()

go_selectted_gene <- enrichGO(gene = selectted_gene, OrgDb = org.Hs.eg.db, keyType = "ENSEMBL", ont = "BP")

go_selectted_gene_df <- as.data.frame(go_selectted_gene)

print(go_selectted_gene_df[1:10,2:7])
```

## 4. Discussion

### 4.1 Conclusion

This paper completes a series of analysis pipelines, starting from raw data, preprocessing, filtering genes, removing outliers identified by PCA, differentially expressed genes, creating classification models using machine learning methods, and GO enrichment analysis. Our supervised model performed very well, with no signs of overfitting or data leakage. From the interpretation of GO enrichment analysis of gene sets based on differential expression analysis and RF model, we obtained common biological insights, that is, the results involve key pathways and processes in tumor biology, such as cell signaling (especially Wnt pathway), extracellular matrix organization, which play an important role in tumorigenesis.

### 4.2 Further study

Future research directions can explore other data preprocessing methods, such as correlation analysis, and LASSO filtering to further reduce the dimension before building the model. At the same time, advanced machine learning methods such as deep learning can also be used to process high-dimensional, low-sample biological data sets. For differentially expressed genes and genes screened from the RF model, we can find common genes from both methods to narrow the range of genes of interest. In terms of research depth, we now use GO enrichment analysis to gain insight into the functional groups of important genes, and then pathway maps can be used to help determine how these genes affect biological systems. In addition, experimental validation of selected genes and integration of multi-omics data will help to gain a deeper understanding of biological mechanisms and seek practical applications of these findings.

## References

1.  Colaprico, A. et al. TCGAbiolinks: an R/Bioconductor package for integrative analysis of TCGA data. Nucleic Acids Res. 44(8), e71 (2016).

2.  Maurya, N.S., Kushwaha, S., Chawade, A. et al. Transcriptome profiling by combined machine learning and statistical R analysis identifies TMEM236 as a potential novel diagnostic biomarker for colorectal cancer. Sci Rep 11, 14304 (2021).

3.  Ringnér, M. What is principal component analysis?. Nat Biotechnol 26, 303–304 (2008).

4.  Rosati, Diletta et al. “Differential gene expression analysis pipelines and bioinformatic tools for the identification of specific biomarkers: A review.” Computational and structural biotechnology journal vol. 23 1154-1168. 1 Mar. 2024.
